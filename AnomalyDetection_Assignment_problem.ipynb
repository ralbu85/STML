{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09673793-0704-46c4-bf9c-03abe274a483",
   "metadata": {},
   "source": [
    "## Special Topics to Machine Learning Project Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddbdfb-eba7-449b-85a3-15f8cda0f13d",
   "metadata": {},
   "source": [
    "* After you run the above code, data will be saved in the df variable. \n",
    "* The dataset is collected from sensors attached to the vessel main engine (to keep the confidential issue, every column name and its sensor value is normalized). \n",
    "* The objective is to train an anomaly detector using Isolation Forest. \n",
    "* There is a label in the dataset (column class), where 0 means a normal datapoint and 1 means an anomalous datapoint. \n",
    "* You will need to preprocess the data, split it into training and testing sets, and then apply the Isolation Forest algorithm to detect anomalies. \n",
    "* Finally, evaluate the performance of your model using appropriate metrics and visualize the results to understand the model's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a9665-ba0d-4ecb-a407-f7c021a7737b",
   "metadata": {},
   "source": [
    "## 1. Importing dataset and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea336d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T07:01:54.440019Z",
     "start_time": "2024-06-05T07:01:51.507887Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyod in /opt/conda/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.1 in /opt/conda/lib/python3.8/site-packages (from pyod) (1.10.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from pyod) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.8/site-packages (from pyod) (1.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from pyod) (3.4.2)\n",
      "Requirement already satisfied: numba>=0.51 in /opt/conda/lib/python3.8/site-packages (from pyod) (0.58.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from pyod) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.8/site-packages (from pyod) (1.22.4)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.8/site-packages (from numba>=0.51->pyod) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.8/site-packages (from numba>=0.51->pyod) (7.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.22.0->pyod) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51->pyod) (3.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pyod) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pyod) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pyod) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pyod) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pyod) (8.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To do the assignment you have to run this cell\n",
    "# After run this code, your colab will install anomaly detection module (but their interface is the same with sklearn)\n",
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b31876e-c0bc-493e-b75b-55ba1a0a52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import necessary modeuls\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Step 1: Load the dataset from pyod\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ralbu85/STML/main/assignment_data.csv.csv')\n",
    "df = df[['Dim_0','Dim_16','Dim_17','Dim_18','Dim_19','Dim_20','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef426c7-166f-4d34-937a-0be4b6a428bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dim_0</th>\n",
       "      <th>Dim_16</th>\n",
       "      <th>Dim_17</th>\n",
       "      <th>Dim_18</th>\n",
       "      <th>Dim_19</th>\n",
       "      <th>Dim_20</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dim_0    Dim_16    Dim_17    Dim_18    Dim_19    Dim_20  class\n",
       "0     0.750000  0.001132  0.080780  0.197324  0.300926  0.225000      0\n",
       "1     0.239583  0.000472  0.164345  0.235786  0.537037  0.165625      0\n",
       "2     0.479167  0.003585  0.130919  0.167224  0.527778  0.118750      0\n",
       "3     0.656250  0.001698  0.091922  0.125418  0.337963  0.129688      0\n",
       "4     0.229167  0.000472  0.142061  0.229097  0.337963  0.235938      0\n",
       "...        ...       ...       ...       ...       ...       ...    ...\n",
       "7195  0.604167  0.004717  0.113092  0.128763  0.379630  0.121875      0\n",
       "7196  0.520833  0.200000  0.030641  0.005017  0.333333  0.005469      1\n",
       "7197  0.520833  0.001434  0.109192  0.147157  0.231481  0.206250      0\n",
       "7198  0.354167  0.005283  0.109192  0.147157  0.333333  0.154688      0\n",
       "7199  0.750000  0.001057  0.109192  0.132107  0.337963  0.137500      0\n",
       "\n",
       "[7200 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of the dataset will be like that\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5dec9-34e0-4afc-9e1c-b9d05440001c",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "* Complete the following cell to calculate the number of normal and abnormal data points.\n",
    "* Save the number of normal data points in the variable 'n_normal' and the number of abnormal data points in the variable 'n_anormal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8fd22b2-4737-4595-85ab-cf5b87bab145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete following code int the cell\n",
    "n_normal = # Complete the code\n",
    "n_anormal = # Complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd05506-6643-4d5e-926e-0ec2901a8a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal data points: 6666\n",
      "Number of abnormal data points: 534\n"
     ]
    }
   ],
   "source": [
    "## Answer checking (If your are correct and run the following cell, the following will be printed.\n",
    "print(f\"Number of normal data points: {n_normal}\")\n",
    "print(f\"Number of abnormal data points: {n_anormal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d080e76-d92b-4eda-8f35-c87dfd677de1",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "* Next we will split the dataset into training/validation/testing\n",
    "* First, 75% of normal data will be used for trining\n",
    "* Second, remaining 25% normal data and entire anormal data will be evenly splitted into validation and testing dataset\n",
    "* Complete the following cell to split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08159c8f-780e-40c4-846a-04f50ce80b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You don't need to code, but you have to run \n",
    "\n",
    "## Split the data with respect to the normal/anormal\n",
    "df_normal = df[df['class']==0]\n",
    "df_anormal = df[df['class']==1]\n",
    "\n",
    "## Splitting data for normal\n",
    "y_normal = df_normal['class']\n",
    "X_normal = df_normal.drop(columns=['class'])\n",
    "\n",
    "## Splitting data for anormal\n",
    "y_anormal = df_anormal['class']\n",
    "X_anormal = df_anormal.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a18470-3185-42fb-8c50-a50195382595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T07:14:12.070887Z",
     "start_time": "2024-06-05T07:14:12.042988Z"
    }
   },
   "outputs": [],
   "source": [
    "## Complete following code int the cell\n",
    "\n",
    "# Split normal data into training (75%) and the remaining (25%)\n",
    "X_normal_train, X_normal_temp, y_normal_train, y_normal_temp = train_test_split( , , , random_state=42) # Complete the code\n",
    "X_normal_val, X_normal_test, y_normal_val, y_normal_test = train_test_split( , , test_size=0.5, random_state=42) # Complete the code\n",
    "\n",
    "# Use all the anormal data for validation and testing\n",
    "X_anormal_val, X_anormal_test, y_anormal_val, y_anormal_test = train_test_split( , , test_size=0.5, random_state=42) # Complete the code\n",
    "\n",
    "# Combine normal and anormal data for validation and testing\n",
    "X_val = np.vstack((X_normal_val, X_anormal_val))\n",
    "y_val = np.hstack((y_normal_val, y_anormal_val))\n",
    "\n",
    "X_test = np.vstack((X_normal_test, X_anormal_test))\n",
    "y_test = np.hstack((y_normal_test, y_anormal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17bb131-4568-4ea6-9e9a-238e2dec070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4999, 6)\n",
      "Shape of X_val: (1100, 6)\n",
      "Shape of X_test: (1101, 6)\n"
     ]
    }
   ],
   "source": [
    "## Answer checking (If your are correct and run the following cell, the following will be printed.\n",
    "print(f\"Shape of X_train: {X_normal_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_val.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f368ba-0a84-427d-bfa9-6873569a1910",
   "metadata": {},
   "source": [
    "## Problem 3.\n",
    "* Next we will perform hyper parameter tuning of Isolation Forest to find the best model using Validation Dataset\n",
    "* Note that IForest model use same API for sklearn\n",
    "* However, we cannot directly run GridSearchCV in this setting\n",
    "* So we will directly iterate the entire hyper parameter spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cebacb67-92a1-4cd1-b1ce-b8207713c3ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T07:15:52.258548Z",
     "start_time": "2024-06-05T07:15:06.769226Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 100, 'max_samples': 'auto', 'contamination': 0.2, 'max_features': 0.8}\n",
      "Best Validation F1-Score: 0.7519260400616332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_samples': ['auto'],\n",
    "    'contamination': [0.1, 0.2,0.3,0.5],\n",
    "    'max_features': [1.0, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "# Function to train and evaluate IsolationForest with given hyperparameters\n",
    "# We will use f1 metric for finding best hyper parameter\n",
    "def train_and_evaluate(params):\n",
    "    iso_forest = IForest(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_samples=params['max_samples'],\n",
    "        contamination=params['contamination'],\n",
    "        max_features=params['max_features'],\n",
    "        random_state=42\n",
    "    )\n",
    "    iso_forest.fit() # Complete the code\n",
    "    y_val_pred = iso_forest.predict() # Complete the code\n",
    "    metric = f1_score(, ) # Complete the code\n",
    "    return metric\n",
    "\n",
    "# Perform manual hyperparameter tuning\n",
    "best_params = None\n",
    "best_metric = -np.inf\n",
    "\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_samples in param_grid['max_samples']:\n",
    "        for contamination in param_grid['contamination']:\n",
    "            for max_features in param_grid['max_features']:\n",
    "                params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_samples': max_samples,\n",
    "                    'contamination': contamination,\n",
    "                    'max_features': max_features\n",
    "                }\n",
    "                metric = train_and_evaluate(params)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_params = params\n",
    "\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Best Validation F1-Score: {best_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74523ea6-00fd-4974-b932-ca3301efd988",
   "metadata": {},
   "source": [
    "## Problem 4.\n",
    "* Now the best params is stored in 'best_params'\n",
    "* You will now re-run the IsolationForest model with best hyper parameters using TEST dataset\n",
    "* Also, we will now check the performance of our best model using various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "237cc793-502f-48af-9d9a-994a75c03ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.5785714285714286\n",
      "Test Recall: 0.9101123595505618\n",
      "Test F1-Score: 0.7074235807860262\n",
      "Test AUC-ROC: 0.8489410718616118\n"
     ]
    }
   ],
   "source": [
    "# Train the best model on the training data\n",
    "best_iso_forest = IForest(\n",
    "    n_estimators=# Complete the code,\n",
    "    max_samples=# Complete the code,\n",
    "    contamination=# Complete the code,\n",
    "    max_features=# Complete the code\n",
    "    random_state=42\n",
    ")\n",
    "best_iso_forest.fit() ## Complete the code\n",
    "\n",
    "# Predicting anomalies on testing set\n",
    "y_test_pred = best_iso_forest.predict() # Complete the code\n",
    "\n",
    "# Evaluating on testing set\n",
    "precision_test = precision_score( , ) # Complete the code,\n",
    "recall_test = recall_score( , ) # Complete the code,\n",
    "f1_test = f1_score( , ) # Complete the code,\n",
    "roc_auc_test = roc_auc_score( , ) # Complete the code,\n",
    "\n",
    "print(f'Test Precision: {precision_test}')\n",
    "print(f'Test Recall: {recall_test}')\n",
    "print(f'Test F1-Score: {f1_test}')\n",
    "print(f'Test AUC-ROC: {roc_auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c93a2-9d5d-40c3-8670-342500c652c1",
   "metadata": {},
   "source": [
    "## Problem 5.\n",
    "* Also we want to examine confusion matrix of our result\n",
    "* Try to extract True Positive, False Positive, True Negative, False Negative\n",
    "* You have to search confusion_matrix API of scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a1bec8-6d1c-4c69-874c-4a58b6afa86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "tp = cm[1][1] # complete the following code\n",
    "fp = cm[1][0] # complete the following code\n",
    "tn = cm[0][0] # complete the following code\n",
    "fn = cm[0][1] # complete the following code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b36fe9-f7b0-451c-9f03-4438a8957199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 243\n",
      "False Positive: 24\n",
      "True Negative: 657\n",
      "False Negative: 177\n"
     ]
    }
   ],
   "source": [
    "## Answer checking (If your are correct and run the following cell, the following will be printed.\n",
    "print(f\"True Positive: {tp}\")\n",
    "print(f\"False Positive: {fp}\")\n",
    "print(f\"True Negative: {tn}\")\n",
    "print(f\"False Negative: {fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477141db-1c53-41ed-9075-97ebafb9010a",
   "metadata": {},
   "source": [
    "## Problem 6 (Extra Credit)\n",
    "* Try to apply the same procedure using PYOD anomaly detection algorithms like LOF, CBOD, ... \n",
    "* Your experment result should be recorded in the following cells..\n",
    "* You have search PYOD in google and try to find the document \n",
    "* Hyper parameter setting depend on student's choice (Avoid too much hyper paramter grids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1f0d4-88e3-4a08-a873-0b0a7626e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the following code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
